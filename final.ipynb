{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Danalmestadi/T5-Capstone/blob/main/final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*italicized text*"
      ],
      "metadata": {
        "id": "LOJT0DTCOnmn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#install packages ğŸ“¦"
      ],
      "metadata": {
        "id": "agNjonWGIV_h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "27ug8JcxNYdA",
        "outputId": "c8b0d58f-9ad3-4b73-9eac-fc578b143e0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.24.7)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.3)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install timm\n",
        "!pip install ultralytics\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing libraries ğŸ“š"
      ],
      "metadata": {
        "id": "JzWP4dLGKCIC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FafFpwtqF9Ed"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading the dataset ğŸ§·"
      ],
      "metadata": {
        "id": "rOrH0DT_I14Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"D4wlgnOPMyBMaKBdCkPA\")\n",
        "project = rf.workspace(\"t5-xhhs7\").project(\"car-collision_system\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov8\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QPI42ZXLI1CW",
        "outputId": "3d04f217-cdd7-4034-98ee-2b96f6558f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.47-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.8.30)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (10.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.3.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.54.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Downloading roboflow-1.1.47-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m80.4/80.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, python-dotenv, idna, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 python-dotenv-1.0.1 requests-toolbelt-1.0.0 roboflow-1.1.47\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Dependency ultralytics==8.0.196 is required but found version=8.3.3, to fix: `pip install ultralytics==8.0.196`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Car-Collision_System-2 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 304887/304887 [00:13<00:00, 22646.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Car-Collision_System-2 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33352/33352 [00:09<00:00, 3639.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX1l7Fd_bQzs"
      },
      "source": [
        "# Training The YOLO Model ğŸ”¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JeCCAu0zoFnH",
        "outputId": "fdf13a93-4b9d-4a2d-ff2e-cd8b1e58bace"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.3 ğŸš€ Python-3.10.12 torch-2.4.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 186 layers, 2,685,148 parameters, 0 gradients, 6.8 GFLOPs\n",
            "\n",
            "video 1/1 (frame 1/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 140.8ms\n",
            "video 1/1 (frame 2/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 122.6ms\n",
            "video 1/1 (frame 3/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 116.1ms\n",
            "video 1/1 (frame 4/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 112.1ms\n",
            "video 1/1 (frame 5/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 110.1ms\n",
            "video 1/1 (frame 6/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 120.4ms\n",
            "video 1/1 (frame 7/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 107.6ms\n",
            "video 1/1 (frame 8/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 122.2ms\n",
            "video 1/1 (frame 9/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 121.6ms\n",
            "video 1/1 (frame 10/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 112.5ms\n",
            "video 1/1 (frame 11/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 119.8ms\n",
            "video 1/1 (frame 12/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 113.2ms\n",
            "video 1/1 (frame 13/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 108.8ms\n",
            "video 1/1 (frame 14/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 122.5ms\n",
            "video 1/1 (frame 15/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 110.2ms\n",
            "video 1/1 (frame 16/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 116.8ms\n",
            "video 1/1 (frame 17/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 125.7ms\n",
            "video 1/1 (frame 18/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 120.1ms\n",
            "video 1/1 (frame 19/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 109.1ms\n",
            "video 1/1 (frame 20/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 126.7ms\n",
            "video 1/1 (frame 21/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 114.2ms\n",
            "video 1/1 (frame 22/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 124.3ms\n",
            "video 1/1 (frame 23/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 114.8ms\n",
            "video 1/1 (frame 24/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 127.5ms\n",
            "video 1/1 (frame 25/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 123.2ms\n",
            "video 1/1 (frame 26/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 111.6ms\n",
            "video 1/1 (frame 27/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 116.6ms\n",
            "video 1/1 (frame 28/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 119.4ms\n",
            "video 1/1 (frame 29/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 120.2ms\n",
            "video 1/1 (frame 30/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 111.6ms\n",
            "video 1/1 (frame 31/141) /content/Dataset_Capstone.mp4: 640x384 1 Bus, 1 car, 121.2ms\n",
            "video 1/1 (frame 32/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 111.1ms\n",
            "video 1/1 (frame 33/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 124.7ms\n",
            "video 1/1 (frame 34/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 112.6ms\n",
            "video 1/1 (frame 35/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 117.2ms\n",
            "video 1/1 (frame 36/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 106.9ms\n",
            "video 1/1 (frame 37/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 116.3ms\n",
            "video 1/1 (frame 38/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 113.6ms\n",
            "video 1/1 (frame 39/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 111.3ms\n",
            "video 1/1 (frame 40/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 108.7ms\n",
            "video 1/1 (frame 41/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 122.8ms\n",
            "video 1/1 (frame 42/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 122.4ms\n",
            "video 1/1 (frame 43/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 109.8ms\n",
            "video 1/1 (frame 44/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 112.2ms\n",
            "video 1/1 (frame 45/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 117.4ms\n",
            "video 1/1 (frame 46/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 124.1ms\n",
            "video 1/1 (frame 47/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 121.9ms\n",
            "video 1/1 (frame 48/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 122.4ms\n",
            "video 1/1 (frame 49/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 136.1ms\n",
            "video 1/1 (frame 50/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 109.7ms\n",
            "video 1/1 (frame 51/141) /content/Dataset_Capstone.mp4: 640x384 3 cars, 112.5ms\n",
            "video 1/1 (frame 52/141) /content/Dataset_Capstone.mp4: 640x384 3 cars, 113.1ms\n",
            "video 1/1 (frame 53/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 116.2ms\n",
            "video 1/1 (frame 54/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 108.3ms\n",
            "video 1/1 (frame 55/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 106.3ms\n",
            "video 1/1 (frame 56/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 115.0ms\n",
            "video 1/1 (frame 57/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 118.6ms\n",
            "video 1/1 (frame 58/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 124.1ms\n",
            "video 1/1 (frame 59/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 124.2ms\n",
            "video 1/1 (frame 60/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 105.5ms\n",
            "video 1/1 (frame 61/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 112.4ms\n",
            "video 1/1 (frame 62/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 109.1ms\n",
            "video 1/1 (frame 63/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 115.1ms\n",
            "video 1/1 (frame 64/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 120.9ms\n",
            "video 1/1 (frame 65/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 116.5ms\n",
            "video 1/1 (frame 66/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 131.2ms\n",
            "video 1/1 (frame 67/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 120.6ms\n",
            "video 1/1 (frame 68/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 124.4ms\n",
            "video 1/1 (frame 69/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 177.1ms\n",
            "video 1/1 (frame 70/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 176.2ms\n",
            "video 1/1 (frame 71/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 181.4ms\n",
            "video 1/1 (frame 72/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 173.0ms\n",
            "video 1/1 (frame 73/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 168.4ms\n",
            "video 1/1 (frame 74/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 181.1ms\n",
            "video 1/1 (frame 75/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 173.1ms\n",
            "video 1/1 (frame 76/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 192.0ms\n",
            "video 1/1 (frame 77/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 175.8ms\n",
            "video 1/1 (frame 78/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 181.0ms\n",
            "video 1/1 (frame 79/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 181.8ms\n",
            "video 1/1 (frame 80/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 174.5ms\n",
            "video 1/1 (frame 81/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 188.1ms\n",
            "video 1/1 (frame 82/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 176.9ms\n",
            "video 1/1 (frame 83/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 141.9ms\n",
            "video 1/1 (frame 84/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 112.5ms\n",
            "video 1/1 (frame 85/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 122.7ms\n",
            "video 1/1 (frame 86/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 109.1ms\n",
            "video 1/1 (frame 87/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 112.4ms\n",
            "video 1/1 (frame 88/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 119.0ms\n",
            "video 1/1 (frame 89/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 109.3ms\n",
            "video 1/1 (frame 90/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 115.9ms\n",
            "video 1/1 (frame 91/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 146.4ms\n",
            "video 1/1 (frame 92/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 116.7ms\n",
            "video 1/1 (frame 93/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 120.9ms\n",
            "video 1/1 (frame 94/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 116.7ms\n",
            "video 1/1 (frame 95/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 109.1ms\n",
            "video 1/1 (frame 96/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 119.1ms\n",
            "video 1/1 (frame 97/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 110.2ms\n",
            "video 1/1 (frame 98/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 111.1ms\n",
            "video 1/1 (frame 99/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 136.4ms\n",
            "video 1/1 (frame 100/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 118.7ms\n",
            "video 1/1 (frame 101/141) /content/Dataset_Capstone.mp4: 640x384 3 cars, 122.7ms\n",
            "video 1/1 (frame 102/141) /content/Dataset_Capstone.mp4: 640x384 3 cars, 109.6ms\n",
            "video 1/1 (frame 103/141) /content/Dataset_Capstone.mp4: 640x384 3 cars, 118.6ms\n",
            "video 1/1 (frame 104/141) /content/Dataset_Capstone.mp4: 640x384 3 cars, 118.3ms\n",
            "video 1/1 (frame 105/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 117.8ms\n",
            "video 1/1 (frame 106/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 120.0ms\n",
            "video 1/1 (frame 107/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 121.7ms\n",
            "video 1/1 (frame 108/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 111.3ms\n",
            "video 1/1 (frame 109/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 117.6ms\n",
            "video 1/1 (frame 110/141) /content/Dataset_Capstone.mp4: 640x384 2 cars, 120.4ms\n",
            "video 1/1 (frame 111/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 119.6ms\n",
            "video 1/1 (frame 112/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 117.5ms\n",
            "video 1/1 (frame 113/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 115.8ms\n",
            "video 1/1 (frame 114/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 123.8ms\n",
            "video 1/1 (frame 115/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 119.7ms\n",
            "video 1/1 (frame 116/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 119.5ms\n",
            "video 1/1 (frame 117/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 115.4ms\n",
            "video 1/1 (frame 118/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 118.4ms\n",
            "video 1/1 (frame 119/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 108.6ms\n",
            "video 1/1 (frame 120/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 120.5ms\n",
            "video 1/1 (frame 121/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 124.2ms\n",
            "video 1/1 (frame 122/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 108.8ms\n",
            "video 1/1 (frame 123/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 156.1ms\n",
            "video 1/1 (frame 124/141) /content/Dataset_Capstone.mp4: 640x384 1 car, 111.2ms\n",
            "video 1/1 (frame 125/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 106.8ms\n",
            "video 1/1 (frame 126/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 120.7ms\n",
            "video 1/1 (frame 127/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 106.8ms\n",
            "video 1/1 (frame 128/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 118.5ms\n",
            "video 1/1 (frame 129/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 119.5ms\n",
            "video 1/1 (frame 130/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 117.1ms\n",
            "video 1/1 (frame 131/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 119.0ms\n",
            "video 1/1 (frame 132/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 117.6ms\n",
            "video 1/1 (frame 133/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 108.1ms\n",
            "video 1/1 (frame 134/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 119.3ms\n",
            "video 1/1 (frame 135/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 110.7ms\n",
            "video 1/1 (frame 136/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 118.4ms\n",
            "video 1/1 (frame 137/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 120.2ms\n",
            "video 1/1 (frame 138/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 124.8ms\n",
            "video 1/1 (frame 139/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 122.0ms\n",
            "video 1/1 (frame 140/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 125.8ms\n",
            "video 1/1 (frame 141/141) /content/Dataset_Capstone.mp4: 640x384 (no detections), 112.7ms\n",
            "Speed: 3.5ms preprocess, 123.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect mode=predict model='/content/final_model.pt' conf=0.50 source='/content/Dataset_Capstone.mp4' save=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujhPAvgMzmD_"
      },
      "source": [
        "--------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFMAt8Wc-6h7"
      },
      "source": [
        "Manually label each image to find out the safe distance threshold."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Making the video path as global varible\n",
        "video_capture = '/content/Video.mp4'"
      ],
      "metadata": {
        "id": "fXO4FeKpKvHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to initialize the video source\n",
        "def initialize_video_source(source):\n",
        "    global video_capture\n",
        "    video_capture = cv2.VideoCapture(source)\n",
        "    if not video_capture.isOpened():\n",
        "        print(\"Error opening video source\")\n",
        "        return False\n",
        "    return True"
      ],
      "metadata": {
        "id": "QwpP47NBKqly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading the MiDas Model ğŸ”·"
      ],
      "metadata": {
        "id": "ERkTJ5xeK8br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MiDaS model for depth estimation\n",
        "def load_midas_model():\n",
        "    midas = torch.hub.load(\"intel-isl/MiDaS\", \"MiDaS_small\")\n",
        "    midas.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    midas.eval()\n",
        "    midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "    transform = midas_transforms.small_transform\n",
        "    return midas, transform"
      ],
      "metadata": {
        "id": "6ky_AfCALFRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Capturing Frame ğŸ“¸"
      ],
      "metadata": {
        "id": "_X6BklnBLIHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Capture a frame from the video\n",
        "def capture_frame():\n",
        "    global video_capture\n",
        "    if video_capture is None:\n",
        "        print(\"Video source not initialized\")\n",
        "        return None\n",
        "    ret, frame = video_capture.read()\n",
        "    if ret:\n",
        "        return frame\n",
        "    else:\n",
        "        print(\"Failed to capture frame\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "Njmf6KQ6LSHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Function to utlize Trained Yolo Model ğŸ”"
      ],
      "metadata": {
        "id": "cSEyBp7LLS9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLO model for object detection\n",
        "def model_object_detection_predict(frame, yolo_model):\n",
        "    results = yolo_model(frame)\n",
        "    return results"
      ],
      "metadata": {
        "id": "Fz8Ugep5LuY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Function to utlize Depth estimation model ğŸ› "
      ],
      "metadata": {
        "id": "Mx51T9DqLvPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_depth_estimation_predict(frame, midas, transform, yolo_bboxes):\n",
        "    # Convert the frame to RGB and prepare it for depth estimation\n",
        "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    input_batch = transform(img).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Run the depth estimation model\n",
        "    with torch.no_grad():\n",
        "        prediction = midas(input_batch)\n",
        "        prediction = torch.nn.functional.interpolate(\n",
        "            prediction.unsqueeze(1),\n",
        "            size=img.shape[:2],\n",
        "            mode=\"bicubic\",\n",
        "            align_corners=False,\n",
        "        ).squeeze()\n",
        "\n",
        "    # Convert the prediction to a normalized depth map\n",
        "    depth_map = prediction.cpu().numpy()\n",
        "    depth_map = cv2.normalize(depth_map, None, 0, 1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_64F)\n",
        "\n",
        "    # Loop through YOLO bounding boxes and calculate distances\n",
        "    distances = []\n",
        "    for bbox in yolo_bboxes:\n",
        "        x_min, y_min, x_max, y_max = map(int, bbox)  # Cast bbox coordinates to integers\n",
        "\n",
        "        # Slice the depth map for the region inside the bounding box\n",
        "        bbox_depth = depth_map[y_min:y_max, x_min:x_max]\n",
        "\n",
        "        # Calculate the mean or median depth within the bounding box\n",
        "        avg_depth = np.mean(bbox_depth)\n",
        "\n",
        "        # Append the result for this bounding box\n",
        "        distances.append(avg_depth)\n",
        "\n",
        "    return depth_map, distances"
      ],
      "metadata": {
        "id": "w_Brff5FMObG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Function to calculate the average depth for a bounding box ğŸ”\n"
      ],
      "metadata": {
        "id": "9sLXi6rEMQNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the average depth for a bounding box\n",
        "def calculate_average_depth(depth_map, bbox):\n",
        "    x1, y1, x2, y2 = map(int, bbox)\n",
        "    roi_depth = depth_map[y1:y2, x1:x2]\n",
        "    return np.mean(roi_depth)"
      ],
      "metadata": {
        "id": "gXiKEBIiMPxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Main Function to test models and Save the Video ğŸŸ¥"
      ],
      "metadata": {
        "id": "jQp59E9iMiwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function to process video and save output with depth estimation and object detection\n",
        "def test_models_and_save_video():\n",
        "    safe_distance = 0.2  # Adjust this value based on your depth map scale\n",
        "\n",
        "    if not initialize_video_source('/content/Video2.mp4'):\n",
        "        return\n",
        "\n",
        "    midas, transform = load_midas_model()\n",
        "    yolo_model = YOLO('/content/final_model.pt')  # Load YOLO model once\n",
        "\n",
        "    # Get video properties\n",
        "    frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    # Create VideoWriter object\n",
        "    out = cv2.VideoWriter('output_video.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
        "\n",
        "    frame_count = 0\n",
        "    while True:\n",
        "        frame = capture_frame()\n",
        "        if frame is None:\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "        print(f\"Processing frame {frame_count}\")\n",
        "\n",
        "        # Object detection\n",
        "        od_results = model_object_detection_predict(frame, yolo_model)\n",
        "        yolo_bboxes = [det[:4].tolist() for det in od_results[0].boxes.data]\n",
        "\n",
        "        # Depth estimation\n",
        "        depth_map, distances = model_depth_estimation_predict(frame, midas, transform, yolo_bboxes)\n",
        "\n",
        "        # Visualize depth map\n",
        "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_map, alpha=255), cv2.COLORMAP_JET)\n",
        "\n",
        "        # Blend original frame with depth colormap\n",
        "        blended = cv2.addWeighted(frame, 0.6, depth_colormap, 0.4, 0)\n",
        "\n",
        "        # Process results\n",
        "        for i, det in enumerate(od_results[0].boxes.data):\n",
        "            bbox = det[:4].tolist()\n",
        "            conf = det[4].item()\n",
        "            cls = int(det[5].item())\n",
        "\n",
        "            avg_depth = distances[i]\n",
        "\n",
        "            # Draw bounding box\n",
        "            x1, y1, x2, y2 = map(int, bbox)\n",
        "            cv2.rectangle(blended, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "            # Add text\n",
        "            label = f\"Class: {cls}, Conf: {conf:.2f}, Depth: {avg_depth:.4f}\"\n",
        "            cv2.putText(blended, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
        "\n",
        "            if avg_depth < safe_distance:\n",
        "                warning = \"WARNING: Too Close!\"\n",
        "                cv2.putText(blended, warning, (x1, y2 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "\n",
        "        # Write the frame\n",
        "        out.write(blended)\n",
        "\n",
        "        # Optional: break after processing a certain number of frames\n",
        "        if frame_count >= 300:  # Process 10 seconds assuming 30 fps\n",
        "            break\n",
        "\n",
        "    video_capture.release()\n",
        "    out.release()\n",
        "    print(\"Processing complete. Output saved as 'output_video.mp4'\")\n",
        "\n",
        "# Run the test and save the video\n",
        "test_models_and_save_video()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "im7ID0rd2791",
        "outputId": "f8ae8ad5-5506-4e3d-c640-a1ccfafe424a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading weights:  None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing frame 1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 (no detections), 201.6ms\n",
            "Speed: 3.4ms preprocess, 201.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2\n",
            "\n",
            "0: 384x640 (no detections), 193.3ms\n",
            "Speed: 3.2ms preprocess, 193.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3\n",
            "\n",
            "0: 384x640 (no detections), 181.4ms\n",
            "Speed: 3.8ms preprocess, 181.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4\n",
            "\n",
            "0: 384x640 (no detections), 190.8ms\n",
            "Speed: 3.7ms preprocess, 190.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 5\n",
            "\n",
            "0: 384x640 (no detections), 188.5ms\n",
            "Speed: 3.4ms preprocess, 188.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 6\n",
            "\n",
            "0: 384x640 (no detections), 202.0ms\n",
            "Speed: 3.2ms preprocess, 202.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 7\n",
            "\n",
            "0: 384x640 (no detections), 199.2ms\n",
            "Speed: 3.3ms preprocess, 199.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 8\n",
            "\n",
            "0: 384x640 (no detections), 212.3ms\n",
            "Speed: 5.5ms preprocess, 212.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 9\n",
            "\n",
            "0: 384x640 (no detections), 187.3ms\n",
            "Speed: 3.8ms preprocess, 187.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 10\n",
            "\n",
            "0: 384x640 (no detections), 123.4ms\n",
            "Speed: 4.9ms preprocess, 123.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 11\n",
            "\n",
            "0: 384x640 (no detections), 120.7ms\n",
            "Speed: 4.8ms preprocess, 120.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 12\n",
            "\n",
            "0: 384x640 (no detections), 117.4ms\n",
            "Speed: 4.4ms preprocess, 117.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 13\n",
            "\n",
            "0: 384x640 (no detections), 122.1ms\n",
            "Speed: 4.7ms preprocess, 122.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 14\n",
            "\n",
            "0: 384x640 (no detections), 132.3ms\n",
            "Speed: 3.7ms preprocess, 132.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 15\n",
            "\n",
            "0: 384x640 (no detections), 116.2ms\n",
            "Speed: 5.2ms preprocess, 116.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 16\n",
            "\n",
            "0: 384x640 (no detections), 117.4ms\n",
            "Speed: 4.5ms preprocess, 117.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 17\n",
            "\n",
            "0: 384x640 (no detections), 148.4ms\n",
            "Speed: 2.9ms preprocess, 148.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 18\n",
            "\n",
            "0: 384x640 (no detections), 118.2ms\n",
            "Speed: 3.2ms preprocess, 118.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 19\n",
            "\n",
            "0: 384x640 (no detections), 121.5ms\n",
            "Speed: 4.3ms preprocess, 121.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 20\n",
            "\n",
            "0: 384x640 (no detections), 150.8ms\n",
            "Speed: 3.3ms preprocess, 150.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 21\n",
            "\n",
            "0: 384x640 (no detections), 123.6ms\n",
            "Speed: 3.1ms preprocess, 123.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 22\n",
            "\n",
            "0: 384x640 (no detections), 120.0ms\n",
            "Speed: 3.4ms preprocess, 120.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 23\n",
            "\n",
            "0: 384x640 (no detections), 129.0ms\n",
            "Speed: 4.5ms preprocess, 129.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 24\n",
            "\n",
            "0: 384x640 (no detections), 117.3ms\n",
            "Speed: 3.5ms preprocess, 117.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 25\n",
            "\n",
            "0: 384x640 (no detections), 121.8ms\n",
            "Speed: 4.7ms preprocess, 121.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 26\n",
            "\n",
            "0: 384x640 (no detections), 136.6ms\n",
            "Speed: 3.4ms preprocess, 136.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 27\n",
            "\n",
            "0: 384x640 (no detections), 118.1ms\n",
            "Speed: 4.8ms preprocess, 118.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 28\n",
            "\n",
            "0: 384x640 (no detections), 121.2ms\n",
            "Speed: 5.4ms preprocess, 121.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 29\n",
            "\n",
            "0: 384x640 (no detections), 135.7ms\n",
            "Speed: 4.2ms preprocess, 135.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 30\n",
            "\n",
            "0: 384x640 (no detections), 123.2ms\n",
            "Speed: 3.3ms preprocess, 123.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 31\n",
            "\n",
            "0: 384x640 (no detections), 119.1ms\n",
            "Speed: 3.5ms preprocess, 119.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 32\n",
            "\n",
            "0: 384x640 (no detections), 126.4ms\n",
            "Speed: 4.4ms preprocess, 126.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 33\n",
            "\n",
            "0: 384x640 (no detections), 140.5ms\n",
            "Speed: 3.2ms preprocess, 140.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 34\n",
            "\n",
            "0: 384x640 (no detections), 116.6ms\n",
            "Speed: 4.7ms preprocess, 116.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 35\n",
            "\n",
            "0: 384x640 (no detections), 118.1ms\n",
            "Speed: 4.5ms preprocess, 118.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 36\n",
            "\n",
            "0: 384x640 (no detections), 135.8ms\n",
            "Speed: 3.2ms preprocess, 135.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 37\n",
            "\n",
            "0: 384x640 (no detections), 122.9ms\n",
            "Speed: 5.2ms preprocess, 122.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 38\n",
            "\n",
            "0: 384x640 (no detections), 122.3ms\n",
            "Speed: 3.4ms preprocess, 122.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 39\n",
            "\n",
            "0: 384x640 (no detections), 126.2ms\n",
            "Speed: 3.4ms preprocess, 126.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 40\n",
            "\n",
            "0: 384x640 (no detections), 139.0ms\n",
            "Speed: 3.4ms preprocess, 139.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 41\n",
            "\n",
            "0: 384x640 (no detections), 205.2ms\n",
            "Speed: 3.4ms preprocess, 205.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 42\n",
            "\n",
            "0: 384x640 (no detections), 183.0ms\n",
            "Speed: 3.6ms preprocess, 183.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 43\n",
            "\n",
            "0: 384x640 (no detections), 199.3ms\n",
            "Speed: 3.6ms preprocess, 199.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 44\n",
            "\n",
            "0: 384x640 (no detections), 186.9ms\n",
            "Speed: 3.3ms preprocess, 186.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 45\n",
            "\n",
            "0: 384x640 (no detections), 189.0ms\n",
            "Speed: 5.3ms preprocess, 189.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 46\n",
            "\n",
            "0: 384x640 (no detections), 207.6ms\n",
            "Speed: 3.3ms preprocess, 207.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 47\n",
            "\n",
            "0: 384x640 (no detections), 188.0ms\n",
            "Speed: 3.8ms preprocess, 188.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 48\n",
            "\n",
            "0: 384x640 (no detections), 190.6ms\n",
            "Speed: 3.4ms preprocess, 190.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 49\n",
            "\n",
            "0: 384x640 (no detections), 124.9ms\n",
            "Speed: 4.1ms preprocess, 124.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 50\n",
            "\n",
            "0: 384x640 (no detections), 121.3ms\n",
            "Speed: 4.5ms preprocess, 121.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 51\n",
            "\n",
            "0: 384x640 (no detections), 120.5ms\n",
            "Speed: 3.7ms preprocess, 120.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 52\n",
            "\n",
            "0: 384x640 (no detections), 124.6ms\n",
            "Speed: 4.3ms preprocess, 124.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 53\n",
            "\n",
            "0: 384x640 (no detections), 127.6ms\n",
            "Speed: 4.0ms preprocess, 127.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 54\n",
            "\n",
            "0: 384x640 (no detections), 138.9ms\n",
            "Speed: 5.1ms preprocess, 138.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 55\n",
            "\n",
            "0: 384x640 (no detections), 124.0ms\n",
            "Speed: 3.3ms preprocess, 124.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 56\n",
            "\n",
            "0: 384x640 (no detections), 128.2ms\n",
            "Speed: 4.4ms preprocess, 128.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 57\n",
            "\n",
            "0: 384x640 (no detections), 132.7ms\n",
            "Speed: 3.8ms preprocess, 132.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 58\n",
            "\n",
            "0: 384x640 1 truck, 121.5ms\n",
            "Speed: 4.6ms preprocess, 121.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 59\n",
            "\n",
            "0: 384x640 1 truck, 123.2ms\n",
            "Speed: 5.1ms preprocess, 123.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 60\n",
            "\n",
            "0: 384x640 1 truck, 123.4ms\n",
            "Speed: 5.0ms preprocess, 123.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 61\n",
            "\n",
            "0: 384x640 (no detections), 125.1ms\n",
            "Speed: 3.1ms preprocess, 125.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 62\n",
            "\n",
            "0: 384x640 (no detections), 121.7ms\n",
            "Speed: 5.3ms preprocess, 121.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 63\n",
            "\n",
            "0: 384x640 (no detections), 116.8ms\n",
            "Speed: 5.0ms preprocess, 116.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 64\n",
            "\n",
            "0: 384x640 (no detections), 130.0ms\n",
            "Speed: 4.8ms preprocess, 130.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 65\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 122.0ms\n",
            "Speed: 4.4ms preprocess, 122.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 66\n",
            "\n",
            "0: 384x640 (no detections), 121.1ms\n",
            "Speed: 5.0ms preprocess, 121.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 67\n",
            "\n",
            "0: 384x640 (no detections), 121.2ms\n",
            "Speed: 4.2ms preprocess, 121.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 68\n",
            "\n",
            "0: 384x640 1 car, 121.2ms\n",
            "Speed: 4.3ms preprocess, 121.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 69\n",
            "\n",
            "0: 384x640 1 car, 119.1ms\n",
            "Speed: 5.3ms preprocess, 119.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 70\n",
            "\n",
            "0: 384x640 1 car, 120.1ms\n",
            "Speed: 3.2ms preprocess, 120.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 71\n",
            "\n",
            "0: 384x640 1 car, 122.6ms\n",
            "Speed: 3.7ms preprocess, 122.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 72\n",
            "\n",
            "0: 384x640 1 car, 122.6ms\n",
            "Speed: 5.0ms preprocess, 122.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 73\n",
            "\n",
            "0: 384x640 1 car, 138.4ms\n",
            "Speed: 4.7ms preprocess, 138.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 74\n",
            "\n",
            "0: 384x640 1 car, 131.1ms\n",
            "Speed: 5.4ms preprocess, 131.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 75\n",
            "\n",
            "0: 384x640 1 car, 121.6ms\n",
            "Speed: 5.4ms preprocess, 121.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 76\n",
            "\n",
            "0: 384x640 (no detections), 136.1ms\n",
            "Speed: 5.1ms preprocess, 136.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 77\n",
            "\n",
            "0: 384x640 (no detections), 122.4ms\n",
            "Speed: 4.0ms preprocess, 122.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 78\n",
            "\n",
            "0: 384x640 (no detections), 117.9ms\n",
            "Speed: 4.5ms preprocess, 117.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 79\n",
            "\n",
            "0: 384x640 (no detections), 192.4ms\n",
            "Speed: 5.0ms preprocess, 192.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 80\n",
            "\n",
            "0: 384x640 (no detections), 183.7ms\n",
            "Speed: 3.9ms preprocess, 183.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 81\n",
            "\n",
            "0: 384x640 (no detections), 192.2ms\n",
            "Speed: 4.1ms preprocess, 192.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 82\n",
            "\n",
            "0: 384x640 (no detections), 194.9ms\n",
            "Speed: 3.7ms preprocess, 194.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 83\n",
            "\n",
            "0: 384x640 (no detections), 204.8ms\n",
            "Speed: 3.6ms preprocess, 204.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 84\n",
            "\n",
            "0: 384x640 (no detections), 187.8ms\n",
            "Speed: 3.5ms preprocess, 187.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 85\n",
            "\n",
            "0: 384x640 (no detections), 206.7ms\n",
            "Speed: 3.3ms preprocess, 206.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 86\n",
            "\n",
            "0: 384x640 (no detections), 202.2ms\n",
            "Speed: 3.4ms preprocess, 202.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 87\n",
            "\n",
            "0: 384x640 (no detections), 200.8ms\n",
            "Speed: 3.4ms preprocess, 200.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 88\n",
            "\n",
            "0: 384x640 1 car, 119.0ms\n",
            "Speed: 3.3ms preprocess, 119.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 89\n",
            "\n",
            "0: 384x640 1 car, 123.0ms\n",
            "Speed: 4.3ms preprocess, 123.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 90\n",
            "\n",
            "0: 384x640 (no detections), 128.7ms\n",
            "Speed: 5.1ms preprocess, 128.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 91\n",
            "\n",
            "0: 384x640 (no detections), 118.7ms\n",
            "Speed: 3.3ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 92\n",
            "\n",
            "0: 384x640 (no detections), 118.8ms\n",
            "Speed: 3.8ms preprocess, 118.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 93\n",
            "\n",
            "0: 384x640 (no detections), 141.9ms\n",
            "Speed: 4.5ms preprocess, 141.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 94\n",
            "\n",
            "0: 384x640 (no detections), 118.7ms\n",
            "Speed: 4.5ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 95\n",
            "\n",
            "0: 384x640 (no detections), 120.6ms\n",
            "Speed: 3.3ms preprocess, 120.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 96\n",
            "\n",
            "0: 384x640 1 truck, 137.4ms\n",
            "Speed: 3.3ms preprocess, 137.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 97\n",
            "\n",
            "0: 384x640 1 truck, 122.0ms\n",
            "Speed: 3.2ms preprocess, 122.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 98\n",
            "\n",
            "0: 384x640 (no detections), 116.6ms\n",
            "Speed: 4.9ms preprocess, 116.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 99\n",
            "\n",
            "0: 384x640 (no detections), 128.3ms\n",
            "Speed: 4.3ms preprocess, 128.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 100\n",
            "\n",
            "0: 384x640 1 truck, 115.7ms\n",
            "Speed: 4.7ms preprocess, 115.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 101\n",
            "\n",
            "0: 384x640 1 car, 118.3ms\n",
            "Speed: 4.2ms preprocess, 118.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 102\n",
            "\n",
            "0: 384x640 1 car, 140.1ms\n",
            "Speed: 4.6ms preprocess, 140.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 103\n",
            "\n",
            "0: 384x640 1 car, 133.2ms\n",
            "Speed: 4.9ms preprocess, 133.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 104\n",
            "\n",
            "0: 384x640 1 car, 118.5ms\n",
            "Speed: 4.2ms preprocess, 118.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 105\n",
            "\n",
            "0: 384x640 (no detections), 133.9ms\n",
            "Speed: 3.7ms preprocess, 133.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 106\n",
            "\n",
            "0: 384x640 (no detections), 133.2ms\n",
            "Speed: 3.5ms preprocess, 133.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 107\n",
            "\n",
            "0: 384x640 (no detections), 124.8ms\n",
            "Speed: 3.2ms preprocess, 124.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 108\n",
            "\n",
            "0: 384x640 (no detections), 128.9ms\n",
            "Speed: 3.6ms preprocess, 128.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 109\n",
            "\n",
            "0: 384x640 (no detections), 131.4ms\n",
            "Speed: 4.0ms preprocess, 131.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 110\n",
            "\n",
            "0: 384x640 (no detections), 118.3ms\n",
            "Speed: 4.1ms preprocess, 118.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 111\n",
            "\n",
            "0: 384x640 1 truck, 131.0ms\n",
            "Speed: 3.4ms preprocess, 131.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 112\n",
            "\n",
            "0: 384x640 1 truck, 130.3ms\n",
            "Speed: 3.3ms preprocess, 130.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 113\n",
            "\n",
            "0: 384x640 1 truck, 119.7ms\n",
            "Speed: 3.6ms preprocess, 119.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 114\n",
            "\n",
            "0: 384x640 1 truck, 129.8ms\n",
            "Speed: 3.3ms preprocess, 129.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 115\n",
            "\n",
            "0: 384x640 1 truck, 125.2ms\n",
            "Speed: 3.3ms preprocess, 125.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 116\n",
            "\n",
            "0: 384x640 (no detections), 120.3ms\n",
            "Speed: 3.9ms preprocess, 120.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 117\n",
            "\n",
            "0: 384x640 (no detections), 120.8ms\n",
            "Speed: 4.5ms preprocess, 120.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 118\n",
            "\n",
            "0: 384x640 1 truck, 121.6ms\n",
            "Speed: 4.6ms preprocess, 121.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 119\n",
            "\n",
            "0: 384x640 1 truck, 184.0ms\n",
            "Speed: 3.3ms preprocess, 184.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 120\n",
            "\n",
            "0: 384x640 1 truck, 189.6ms\n",
            "Speed: 4.4ms preprocess, 189.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 121\n",
            "\n",
            "0: 384x640 (no detections), 184.8ms\n",
            "Speed: 3.5ms preprocess, 184.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 122\n",
            "\n",
            "0: 384x640 (no detections), 194.2ms\n",
            "Speed: 3.9ms preprocess, 194.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 123\n",
            "\n",
            "0: 384x640 (no detections), 183.7ms\n",
            "Speed: 3.6ms preprocess, 183.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 124\n",
            "\n",
            "0: 384x640 (no detections), 200.5ms\n",
            "Speed: 3.5ms preprocess, 200.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 125\n",
            "\n",
            "0: 384x640 (no detections), 204.6ms\n",
            "Speed: 3.3ms preprocess, 204.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 126\n",
            "\n",
            "0: 384x640 (no detections), 202.4ms\n",
            "Speed: 3.3ms preprocess, 202.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 127\n",
            "\n",
            "0: 384x640 (no detections), 191.1ms\n",
            "Speed: 3.4ms preprocess, 191.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 128\n",
            "\n",
            "0: 384x640 (no detections), 121.8ms\n",
            "Speed: 3.4ms preprocess, 121.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 129\n",
            "\n",
            "0: 384x640 (no detections), 120.3ms\n",
            "Speed: 3.4ms preprocess, 120.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 130\n",
            "\n",
            "0: 384x640 (no detections), 123.6ms\n",
            "Speed: 3.4ms preprocess, 123.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 131\n",
            "\n",
            "0: 384x640 (no detections), 121.2ms\n",
            "Speed: 4.3ms preprocess, 121.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 132\n",
            "\n",
            "0: 384x640 (no detections), 121.0ms\n",
            "Speed: 3.2ms preprocess, 121.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 133\n",
            "\n",
            "0: 384x640 (no detections), 133.7ms\n",
            "Speed: 3.5ms preprocess, 133.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 134\n",
            "\n",
            "0: 384x640 (no detections), 123.6ms\n",
            "Speed: 4.3ms preprocess, 123.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 135\n",
            "\n",
            "0: 384x640 1 car, 123.8ms\n",
            "Speed: 4.8ms preprocess, 123.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 136\n",
            "\n",
            "0: 384x640 (no detections), 132.6ms\n",
            "Speed: 5.0ms preprocess, 132.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 137\n",
            "\n",
            "0: 384x640 (no detections), 129.1ms\n",
            "Speed: 3.5ms preprocess, 129.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 138\n",
            "\n",
            "0: 384x640 (no detections), 119.0ms\n",
            "Speed: 4.9ms preprocess, 119.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 139\n",
            "\n",
            "0: 384x640 (no detections), 132.9ms\n",
            "Speed: 3.4ms preprocess, 132.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 140\n",
            "\n",
            "0: 384x640 (no detections), 120.6ms\n",
            "Speed: 3.5ms preprocess, 120.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 141\n",
            "\n",
            "0: 384x640 1 car, 120.8ms\n",
            "Speed: 5.1ms preprocess, 120.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 142\n",
            "\n",
            "0: 384x640 1 car, 123.9ms\n",
            "Speed: 4.0ms preprocess, 123.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 143\n",
            "\n",
            "0: 384x640 1 car, 122.9ms\n",
            "Speed: 5.1ms preprocess, 122.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 144\n",
            "\n",
            "0: 384x640 1 car, 122.1ms\n",
            "Speed: 3.5ms preprocess, 122.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 145\n",
            "\n",
            "0: 384x640 2 cars, 125.0ms\n",
            "Speed: 3.3ms preprocess, 125.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 146\n",
            "\n",
            "0: 384x640 1 car, 125.5ms\n",
            "Speed: 4.5ms preprocess, 125.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 147\n",
            "\n",
            "0: 384x640 1 car, 118.4ms\n",
            "Speed: 5.4ms preprocess, 118.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 148\n",
            "\n",
            "0: 384x640 1 car, 119.7ms\n",
            "Speed: 5.3ms preprocess, 119.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 149\n",
            "\n",
            "0: 384x640 1 car, 124.3ms\n",
            "Speed: 4.0ms preprocess, 124.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 150\n",
            "\n",
            "0: 384x640 1 car, 118.6ms\n",
            "Speed: 3.6ms preprocess, 118.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 151\n",
            "\n",
            "0: 384x640 1 car, 122.3ms\n",
            "Speed: 3.8ms preprocess, 122.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 152\n",
            "\n",
            "0: 384x640 1 car, 129.5ms\n",
            "Speed: 3.4ms preprocess, 129.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 153\n",
            "\n",
            "0: 384x640 (no detections), 116.0ms\n",
            "Speed: 4.8ms preprocess, 116.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 154\n",
            "\n",
            "0: 384x640 (no detections), 116.8ms\n",
            "Speed: 4.5ms preprocess, 116.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 155\n",
            "\n",
            "0: 384x640 (no detections), 148.2ms\n",
            "Speed: 4.3ms preprocess, 148.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 156\n",
            "\n",
            "0: 384x640 (no detections), 117.6ms\n",
            "Speed: 3.2ms preprocess, 117.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 157\n",
            "\n",
            "0: 384x640 (no detections), 117.6ms\n",
            "Speed: 4.4ms preprocess, 117.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 158\n",
            "\n",
            "0: 384x640 1 car, 193.2ms\n",
            "Speed: 4.6ms preprocess, 193.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 159\n",
            "\n",
            "0: 384x640 1 car, 185.4ms\n",
            "Speed: 4.8ms preprocess, 185.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 160\n",
            "\n",
            "0: 384x640 1 car, 204.7ms\n",
            "Speed: 3.8ms preprocess, 204.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 161\n",
            "\n",
            "0: 384x640 (no detections), 177.7ms\n",
            "Speed: 3.9ms preprocess, 177.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 162\n",
            "\n",
            "0: 384x640 (no detections), 195.4ms\n",
            "Speed: 4.1ms preprocess, 195.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 163\n",
            "\n",
            "0: 384x640 (no detections), 183.2ms\n",
            "Speed: 3.4ms preprocess, 183.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 164\n",
            "\n",
            "0: 384x640 (no detections), 223.3ms\n",
            "Speed: 3.5ms preprocess, 223.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 165\n",
            "\n",
            "0: 384x640 (no detections), 197.9ms\n",
            "Speed: 3.4ms preprocess, 197.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 166\n",
            "\n",
            "0: 384x640 (no detections), 194.1ms\n",
            "Speed: 3.4ms preprocess, 194.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 167\n",
            "\n",
            "0: 384x640 (no detections), 119.0ms\n",
            "Speed: 3.3ms preprocess, 119.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 168\n",
            "\n",
            "0: 384x640 (no detections), 121.2ms\n",
            "Speed: 3.7ms preprocess, 121.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 169\n",
            "\n",
            "0: 384x640 (no detections), 121.3ms\n",
            "Speed: 4.4ms preprocess, 121.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 170\n",
            "\n",
            "0: 384x640 (no detections), 120.5ms\n",
            "Speed: 3.1ms preprocess, 120.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 171\n",
            "\n",
            "0: 384x640 (no detections), 118.1ms\n",
            "Speed: 4.5ms preprocess, 118.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 172\n",
            "\n",
            "0: 384x640 (no detections), 116.6ms\n",
            "Speed: 5.2ms preprocess, 116.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 173\n",
            "\n",
            "0: 384x640 (no detections), 118.4ms\n",
            "Speed: 4.3ms preprocess, 118.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 174\n",
            "\n",
            "0: 384x640 (no detections), 122.9ms\n",
            "Speed: 3.5ms preprocess, 122.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 175\n",
            "\n",
            "0: 384x640 2 cars, 127.9ms\n",
            "Speed: 3.3ms preprocess, 127.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 176\n",
            "\n",
            "0: 384x640 2 cars, 128.6ms\n",
            "Speed: 4.5ms preprocess, 128.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 177\n",
            "\n",
            "0: 384x640 1 car, 120.2ms\n",
            "Speed: 3.5ms preprocess, 120.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 178\n",
            "\n",
            "0: 384x640 1 car, 129.3ms\n",
            "Speed: 4.4ms preprocess, 129.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 179\n",
            "\n",
            "0: 384x640 1 car, 127.9ms\n",
            "Speed: 3.8ms preprocess, 127.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 180\n",
            "\n",
            "0: 384x640 (no detections), 116.9ms\n",
            "Speed: 3.2ms preprocess, 116.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 181\n",
            "\n",
            "0: 384x640 3 cars, 144.5ms\n",
            "Speed: 3.2ms preprocess, 144.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 182\n",
            "\n",
            "0: 384x640 3 cars, 118.9ms\n",
            "Speed: 3.1ms preprocess, 118.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 183\n",
            "\n",
            "0: 384x640 4 cars, 123.8ms\n",
            "Speed: 4.8ms preprocess, 123.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 184\n",
            "\n",
            "0: 384x640 4 cars, 142.3ms\n",
            "Speed: 4.2ms preprocess, 142.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 185\n",
            "\n",
            "0: 384x640 5 cars, 115.9ms\n",
            "Speed: 4.9ms preprocess, 115.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 186\n",
            "\n",
            "0: 384x640 3 cars, 116.9ms\n",
            "Speed: 4.8ms preprocess, 116.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 187\n",
            "\n",
            "0: 384x640 3 cars, 140.8ms\n",
            "Speed: 4.1ms preprocess, 140.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 188\n",
            "\n",
            "0: 384x640 4 cars, 119.2ms\n",
            "Speed: 4.4ms preprocess, 119.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 189\n",
            "\n",
            "0: 384x640 4 cars, 113.9ms\n",
            "Speed: 5.1ms preprocess, 113.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 190\n",
            "\n",
            "0: 384x640 1 car, 135.9ms\n",
            "Speed: 3.7ms preprocess, 135.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 191\n",
            "\n",
            "0: 384x640 1 car, 118.5ms\n",
            "Speed: 5.2ms preprocess, 118.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 192\n",
            "\n",
            "0: 384x640 1 car, 119.4ms\n",
            "Speed: 4.2ms preprocess, 119.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 193\n",
            "\n",
            "0: 384x640 2 cars, 134.4ms\n",
            "Speed: 4.0ms preprocess, 134.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 194\n",
            "\n",
            "0: 384x640 2 cars, 118.8ms\n",
            "Speed: 3.4ms preprocess, 118.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 195\n",
            "\n",
            "0: 384x640 4 cars, 128.4ms\n",
            "Speed: 3.5ms preprocess, 128.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 196\n",
            "\n",
            "0: 384x640 2 cars, 136.3ms\n",
            "Speed: 4.3ms preprocess, 136.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 197\n",
            "\n",
            "0: 384x640 2 cars, 190.4ms\n",
            "Speed: 4.4ms preprocess, 190.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 198\n",
            "\n",
            "0: 384x640 (no detections), 186.8ms\n",
            "Speed: 3.5ms preprocess, 186.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 199\n",
            "\n",
            "0: 384x640 (no detections), 186.0ms\n",
            "Speed: 6.1ms preprocess, 186.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 200\n",
            "\n",
            "0: 384x640 1 truck, 195.9ms\n",
            "Speed: 6.8ms preprocess, 195.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 201\n",
            "\n",
            "0: 384x640 3 cars, 186.4ms\n",
            "Speed: 5.5ms preprocess, 186.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 202\n",
            "\n",
            "0: 384x640 4 cars, 188.0ms\n",
            "Speed: 3.9ms preprocess, 188.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 203\n",
            "\n",
            "0: 384x640 1 Bus, 5 cars, 207.7ms\n",
            "Speed: 3.3ms preprocess, 207.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 204\n",
            "\n",
            "0: 384x640 1 Bus, 5 cars, 221.0ms\n",
            "Speed: 3.3ms preprocess, 221.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 205\n",
            "\n",
            "0: 384x640 2 cars, 145.1ms\n",
            "Speed: 3.6ms preprocess, 145.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 206\n",
            "\n",
            "0: 384x640 3 cars, 123.3ms\n",
            "Speed: 4.9ms preprocess, 123.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 207\n",
            "\n",
            "0: 384x640 3 cars, 121.0ms\n",
            "Speed: 3.7ms preprocess, 121.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 208\n",
            "\n",
            "0: 384x640 3 cars, 120.0ms\n",
            "Speed: 4.5ms preprocess, 120.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 209\n",
            "\n",
            "0: 384x640 4 cars, 122.5ms\n",
            "Speed: 3.1ms preprocess, 122.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 210\n",
            "\n",
            "0: 384x640 2 cars, 123.0ms\n",
            "Speed: 3.5ms preprocess, 123.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 211\n",
            "\n",
            "0: 384x640 2 cars, 118.6ms\n",
            "Speed: 6.1ms preprocess, 118.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 212\n",
            "\n",
            "0: 384x640 2 cars, 118.4ms\n",
            "Speed: 4.5ms preprocess, 118.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 213\n",
            "\n",
            "0: 384x640 2 cars, 123.6ms\n",
            "Speed: 4.6ms preprocess, 123.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 214\n",
            "\n",
            "0: 384x640 2 cars, 122.5ms\n",
            "Speed: 5.4ms preprocess, 122.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 215\n",
            "\n",
            "0: 384x640 1 car, 118.1ms\n",
            "Speed: 4.5ms preprocess, 118.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 216\n",
            "\n",
            "0: 384x640 1 car, 125.2ms\n",
            "Speed: 3.9ms preprocess, 125.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 217\n",
            "\n",
            "0: 384x640 1 car, 117.7ms\n",
            "Speed: 4.3ms preprocess, 117.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 218\n",
            "\n",
            "0: 384x640 3 cars, 121.8ms\n",
            "Speed: 4.9ms preprocess, 121.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 219\n",
            "\n",
            "0: 384x640 3 cars, 136.9ms\n",
            "Speed: 5.7ms preprocess, 136.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 220\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 118.0ms\n",
            "Speed: 3.1ms preprocess, 118.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 221\n",
            "\n",
            "0: 384x640 2 cars, 124.2ms\n",
            "Speed: 5.2ms preprocess, 124.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 222\n",
            "\n",
            "0: 384x640 2 cars, 144.0ms\n",
            "Speed: 4.3ms preprocess, 144.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 223\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 120.2ms\n",
            "Speed: 5.9ms preprocess, 120.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 224\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 120.2ms\n",
            "Speed: 3.2ms preprocess, 120.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 225\n",
            "\n",
            "0: 384x640 1 Bus, 143.0ms\n",
            "Speed: 3.2ms preprocess, 143.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 226\n",
            "\n",
            "0: 384x640 1 Bus, 120.3ms\n",
            "Speed: 3.2ms preprocess, 120.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 227\n",
            "\n",
            "0: 384x640 1 Bus, 121.4ms\n",
            "Speed: 3.6ms preprocess, 121.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 228\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 142.0ms\n",
            "Speed: 3.9ms preprocess, 142.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 229\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 118.9ms\n",
            "Speed: 3.2ms preprocess, 118.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 230\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 117.2ms\n",
            "Speed: 4.2ms preprocess, 117.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 231\n",
            "\n",
            "0: 384x640 1 Bus, 138.1ms\n",
            "Speed: 3.7ms preprocess, 138.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 232\n",
            "\n",
            "0: 384x640 1 Bus, 115.8ms\n",
            "Speed: 3.3ms preprocess, 115.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 233\n",
            "\n",
            "0: 384x640 (no detections), 120.3ms\n",
            "Speed: 4.5ms preprocess, 120.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 234\n",
            "\n",
            "0: 384x640 (no detections), 132.6ms\n",
            "Speed: 3.4ms preprocess, 132.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 235\n",
            "\n",
            "0: 384x640 (no detections), 123.0ms\n",
            "Speed: 3.9ms preprocess, 123.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 236\n",
            "\n",
            "0: 384x640 (no detections), 186.7ms\n",
            "Speed: 6.0ms preprocess, 186.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 237\n",
            "\n",
            "0: 384x640 (no detections), 201.7ms\n",
            "Speed: 3.4ms preprocess, 201.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 238\n",
            "\n",
            "0: 384x640 1 Bus, 2 cars, 181.3ms\n",
            "Speed: 3.6ms preprocess, 181.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 239\n",
            "\n",
            "0: 384x640 1 Bus, 2 cars, 205.1ms\n",
            "Speed: 3.5ms preprocess, 205.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 240\n",
            "\n",
            "0: 384x640 1 Bus, 3 cars, 194.4ms\n",
            "Speed: 3.6ms preprocess, 194.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 241\n",
            "\n",
            "0: 384x640 1 Bus, 3 cars, 214.4ms\n",
            "Speed: 3.3ms preprocess, 214.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 242\n",
            "\n",
            "0: 384x640 1 Bus, 3 cars, 230.0ms\n",
            "Speed: 3.4ms preprocess, 230.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 243\n",
            "\n",
            "0: 384x640 1 Bus, 3 cars, 195.2ms\n",
            "Speed: 5.0ms preprocess, 195.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 244\n",
            "\n",
            "0: 384x640 1 Bus, 3 cars, 119.5ms\n",
            "Speed: 3.7ms preprocess, 119.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 245\n",
            "\n",
            "0: 384x640 1 Bus, 2 cars, 122.3ms\n",
            "Speed: 3.2ms preprocess, 122.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 246\n",
            "\n",
            "0: 384x640 1 Bus, 2 cars, 118.4ms\n",
            "Speed: 4.1ms preprocess, 118.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 247\n",
            "\n",
            "0: 384x640 1 Bus, 2 cars, 126.4ms\n",
            "Speed: 3.2ms preprocess, 126.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 248\n",
            "\n",
            "0: 384x640 2 cars, 123.2ms\n",
            "Speed: 5.3ms preprocess, 123.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 249\n",
            "\n",
            "0: 384x640 1 Bus, 2 cars, 123.2ms\n",
            "Speed: 3.4ms preprocess, 123.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 250\n",
            "\n",
            "0: 384x640 1 Bus, 119.6ms\n",
            "Speed: 3.5ms preprocess, 119.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 251\n",
            "\n",
            "0: 384x640 1 car, 125.3ms\n",
            "Speed: 5.8ms preprocess, 125.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 252\n",
            "\n",
            "0: 384x640 1 car, 119.4ms\n",
            "Speed: 3.8ms preprocess, 119.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 253\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 120.7ms\n",
            "Speed: 4.8ms preprocess, 120.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 254\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 128.1ms\n",
            "Speed: 4.1ms preprocess, 128.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 255\n",
            "\n",
            "0: 384x640 1 car, 121.3ms\n",
            "Speed: 4.8ms preprocess, 121.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 256\n",
            "\n",
            "0: 384x640 1 car, 117.8ms\n",
            "Speed: 4.0ms preprocess, 117.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 257\n",
            "\n",
            "0: 384x640 1 car, 131.7ms\n",
            "Speed: 3.2ms preprocess, 131.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 258\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 123.9ms\n",
            "Speed: 5.1ms preprocess, 123.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 259\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 132.2ms\n",
            "Speed: 4.0ms preprocess, 132.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 260\n",
            "\n",
            "0: 384x640 2 cars, 134.9ms\n",
            "Speed: 4.3ms preprocess, 134.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 261\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 121.6ms\n",
            "Speed: 5.0ms preprocess, 121.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 262\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 133.6ms\n",
            "Speed: 5.3ms preprocess, 133.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 263\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 138.3ms\n",
            "Speed: 6.0ms preprocess, 138.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 264\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 123.4ms\n",
            "Speed: 4.4ms preprocess, 123.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 265\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 121.6ms\n",
            "Speed: 4.5ms preprocess, 121.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 266\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 141.4ms\n",
            "Speed: 2.4ms preprocess, 141.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 267\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 123.6ms\n",
            "Speed: 3.6ms preprocess, 123.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 268\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 119.5ms\n",
            "Speed: 4.5ms preprocess, 119.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 269\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 131.8ms\n",
            "Speed: 5.2ms preprocess, 131.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 270\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 123.2ms\n",
            "Speed: 3.3ms preprocess, 123.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 271\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 118.9ms\n",
            "Speed: 4.3ms preprocess, 118.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 272\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 137.1ms\n",
            "Speed: 4.5ms preprocess, 137.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 273\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 126.1ms\n",
            "Speed: 4.4ms preprocess, 126.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 274\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 189.1ms\n",
            "Speed: 5.4ms preprocess, 189.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 275\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 184.9ms\n",
            "Speed: 3.4ms preprocess, 184.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 276\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 186.4ms\n",
            "Speed: 3.5ms preprocess, 186.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 277\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 188.7ms\n",
            "Speed: 3.3ms preprocess, 188.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 278\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 197.8ms\n",
            "Speed: 3.4ms preprocess, 197.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 279\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 196.7ms\n",
            "Speed: 3.4ms preprocess, 196.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 280\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 196.7ms\n",
            "Speed: 3.5ms preprocess, 196.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 281\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 190.7ms\n",
            "Speed: 4.6ms preprocess, 190.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 282\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 120.0ms\n",
            "Speed: 3.4ms preprocess, 120.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 283\n",
            "\n",
            "0: 384x640 1 Bus, 132.3ms\n",
            "Speed: 3.9ms preprocess, 132.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 284\n",
            "\n",
            "0: 384x640 1 Bus, 125.7ms\n",
            "Speed: 4.5ms preprocess, 125.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 285\n",
            "\n",
            "0: 384x640 1 Bus, 126.2ms\n",
            "Speed: 3.4ms preprocess, 126.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 286\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 132.0ms\n",
            "Speed: 5.0ms preprocess, 132.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 287\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 128.3ms\n",
            "Speed: 3.3ms preprocess, 128.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 288\n",
            "\n",
            "0: 384x640 1 Bus, 121.4ms\n",
            "Speed: 3.6ms preprocess, 121.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 289\n",
            "\n",
            "0: 384x640 1 Bus, 132.3ms\n",
            "Speed: 4.1ms preprocess, 132.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 290\n",
            "\n",
            "0: 384x640 1 Bus, 122.4ms\n",
            "Speed: 3.3ms preprocess, 122.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 291\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 121.3ms\n",
            "Speed: 6.7ms preprocess, 121.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 292\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 134.2ms\n",
            "Speed: 4.7ms preprocess, 134.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 293\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 128.4ms\n",
            "Speed: 4.3ms preprocess, 128.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 294\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 116.3ms\n",
            "Speed: 4.2ms preprocess, 116.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 295\n",
            "\n",
            "0: 384x640 1 Bus, 133.0ms\n",
            "Speed: 5.7ms preprocess, 133.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 296\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 117.1ms\n",
            "Speed: 3.4ms preprocess, 117.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 297\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 119.8ms\n",
            "Speed: 5.4ms preprocess, 119.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 298\n",
            "\n",
            "0: 384x640 1 Bus, 146.9ms\n",
            "Speed: 5.9ms preprocess, 146.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 299\n",
            "\n",
            "0: 384x640 1 Bus, 118.7ms\n",
            "Speed: 5.2ms preprocess, 118.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 300\n",
            "\n",
            "0: 384x640 1 Bus, 1 car, 118.2ms\n",
            "Speed: 3.2ms preprocess, 118.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing complete. Output saved as 'output_video.mp4'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}